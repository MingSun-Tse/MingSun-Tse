### Hi there ðŸ‘‹

I am a Ph.D. candidate at [SMILE Lab](https://web.northeastern.edu/smilelab/) of Northeastern University (Boston, USA). Before that, I spent seven wonderful years at Zhejiang Univeristy (Hangzhou, China) to get my B.E. and M.S. degrees. 

I am interested in a variety of topics in computer vision and machine learning. My research works orbit [efficient deep learning](https://github.com/MingSun-Tse/EfficientDNNs) (a.k.a. model compression), spanning from the most common image classifcation task ([GReg](https://github.com/MingSun-Tse/Regularization-Pruning), [Awesome-PaI](https://github.com/MingSun-Tse/Awesome-Pruning-at-Initialization), [TPP](https://github.com/MingSun-Tse/TPP)) to neural style transfer ([Collaborative-Distillation](https://github.com/MingSun-Tse/Collaborative-Distillation)), single image super-resolution ([ASSL](https://github.com/MingSun-Tse/ASSL), [SRP](https://github.com/MingSun-Tse/SRP)), and 3D novel view synthesis ([R2L](https://snap-research.github.io/R2L/), [MobileR2L](https://snap-research.github.io/MobileR2L/)).

I do my best towards [easily reproducible](https://github.com/MingSun-Tse/smilelogging) research. 

ðŸ”¥ NEWS: **[NeurIPS'23]** We are excited to present [SnapFusion](https://snap-research.github.io/SnapFusion/), a super-efficient mobile diffusion model that can do text-to-image generation in **less than 2s**ðŸš€ on mobile devices! [[Arxiv](https://arxiv.org/abs/2306.00980)] [[Webpage](https://snap-research.github.io/SnapFusion/)] <br/>
ðŸ”¥ NEWS: **[CVPR'23]** Check out our new blazing fastðŸš€ neural rendering model on mobile devices: MobileR2L (the lightweight version of [R2L](https://snap-research.github.io/R2L/)), can render **1008x756** images at **56fps** on **iPhone13** [[Arxiv](https://arxiv.org/abs/2212.08057)] [[Code](https://github.com/snap-research/MobileR2L)] <br/>
ðŸ”¥ NEWS: **[ICLR'23]** Check out the very first trainability-preserving filter pruning method: TPP [[Arxiv](https://arxiv.org/abs/2207.12534)] [[Code](https://github.com/MingSun-Tse/TPP)] <br/>
ðŸ”¥ NEWS: Check out our preprint work that deciphers the *so confusing* benchmark situation in neural network (filter) pruning: [[Arxiv](https://arxiv.org/abs/2301.05219)] [[Code](https://github.com/mingsun-tse/why-the-state-of-pruning-so-confusing)] <br/>
âœ¨ NEWS: Check out our investigation of what makes a "good" data augmentation in knowledge distillation, in NeurIPS 2022: [[Webpage](https://huanwang.tech/Good-DA-in-KD)] [[Code](https://github.com/MingSun-Tse/Good-DA-in-KD)] <br/>
âœ¨ NEWS: Check out our Efficient NeRF project via distillation, in ECCV 2022: [[R2L](https://snap-research.github.io/R2L/)] <br/>


![Github stats](https://github-readme-stats.vercel.app/api?username=mingsun-tse&theme=default&show_icons=true&count_private=true&layout=compact)


<!--
 _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- ðŸ”­ Iâ€™m currently working on ...
- ðŸŒ± Iâ€™m currently learning ...
- ðŸ‘¯ Iâ€™m looking to collaborate on ...
- ðŸ¤” Iâ€™m looking for help with ...
- ðŸ’¬ Ask me about ...
- ðŸ“« How to reach me: ...
- ðŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
-->
